{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "'''\n",
    "read in both data and dictionary files, intercept with columes that describe volume\n",
    "params: path to both files\n",
    "param: keyword for filter out area of interest\n",
    "return: dataframe of patientID, VISCODE, exam date and volumes of all regions in dictionary \n",
    "'''\n",
    "def read_csv(file, dictfile, keyword):\n",
    "    df = pd.read_csv(file)\n",
    "    dict_df = pd.read_csv(dictfile)\n",
    "    #print(df.head())\n",
    "\n",
    "    #filter out rows only with Volume\n",
    "    dict_df = dict_df[dict_df[\"TEXT\"].str.contains(keyword, case=False, na=False)]\n",
    "    STcodes = dict_df['FLDNAME'].values\n",
    "    #print(dict_df.head())\n",
    "    #print(STcodes)\n",
    "\n",
    "    extra_cols = ['RID','VISCODE','EXAMDATE']\n",
    "    column_needed = np.concatenate([extra_cols, STcodes])\n",
    "    \n",
    "    #cross reference df with dict_df\n",
    "    df = df.loc[:,column_needed]\n",
    "    return df\n",
    "\n",
    "'''\n",
    "create dir in current folder to save all correlation matrices\n",
    "'''\n",
    "def make_dir(dirname):\n",
    "    parent_dir = os.getcwd()\n",
    "    path = os.path.join(parent_dir, dirname)\n",
    "    os.mkdir(path)\n",
    "    \n",
    "'''\n",
    "get correlation matrix per patient for all structures in the data file w.r.t volume\n",
    "params: df is the processed dataframe with all data, path is the path for output dir\n",
    "return: no return, saves all corr-mat to file\n",
    "'''\n",
    "def get_corr_mat(df, path):\n",
    "    # get patients\n",
    "    patients = np.unique(df['RID'].values)\n",
    "    #print(patients)\n",
    "\n",
    "    #I think fill rows with NA values at patient level for now, see how to do later\n",
    "    for p in patients:\n",
    "        pat_df = df[df['RID'] == p]\n",
    "\n",
    "        ##only take into account of patients with more than 3 rows\n",
    "        ##since 2 rows produce matrix of 1 and -1, and 1 row produces NA\n",
    "        if len(pat_df.index) > 2:\n",
    "            #convert to datetime, then sort by time\n",
    "            try:\n",
    "                pat_df['EXAMDATE'] = pd.to_datetime(pat_df['EXAMDATE'], format='%m/%d/%y')\n",
    "            except:\n",
    "                pat_df['EXAMDATE'] = pd.to_datetime(pat_df['EXAMDATE'], format='%Y-%m-%d')\n",
    "            pat_df = pat_df.sort_values(by=['EXAMDATE'])\n",
    "            #print(pat_df)\n",
    "\n",
    "            #drop columns with all NAs\n",
    "            pat_df = pat_df.dropna(axis=1, how='all')\n",
    "            ##filling NA values, forward fill for now, MAY CHANGE!!!!\n",
    "            pat_df = pat_df.fillna(method='ffill')\n",
    "            #drop unnecessary rows for correlation matrix\n",
    "            pad_df = pat_df.drop(['RID','VISCODE','EXAMDATE'],axis=1)\n",
    "            corr_mat = pad_df.corr()\n",
    "\n",
    "            #output to csv for comparison later, maybe in R?\n",
    "            out_path = path + '/Patient_' + str(p) + '.csv'\n",
    "            corr_mat.to_csv(out_path)\n",
    "\n",
    "            ##visualization with sns\n",
    "            #plot = sns.clustermap(corr_mat, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-f6fdb70137e6>:61: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pat_df['EXAMDATE'] = pd.to_datetime(pat_df['EXAMDATE'], format='%m/%d/%y')\n",
      "<ipython-input-31-f6fdb70137e6>:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pat_df['EXAMDATE'] = pd.to_datetime(pat_df['EXAMDATE'], format='%Y-%m-%d')\n"
     ]
    }
   ],
   "source": [
    "##iterate through all good studies and generate corr matrix\n",
    "file_df = pd.read_csv('ADNI1_good_files.csv')\n",
    "for i in range(len(file_df.index)):\n",
    "    study = file_df.iloc[i,0]\n",
    "    filename = 'ADNI1_all_data/' + str(file_df.iloc[i,1])\n",
    "    dictname = 'ADNI1_all_data/' + str(file_df.iloc[i,2])\n",
    "    keyword = \"Volume\"\n",
    "    \n",
    "    df = read_csv(filename, dictname, keyword)\n",
    "    make_dir(study)\n",
    "    get_corr_mat(df, study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-36-0cc9f6594295>:58: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pat_df['EXAMDATE'] = pd.to_datetime(pat_df['EXAMDATE'], format='%m/%d/%y')\n"
     ]
    }
   ],
   "source": [
    "##### UCSF Cross Sectional Free Surfer 3T data, this will be the baseline\n",
    "file = 'ADNI1_all_data/FOXLABBSI_03_27_20.csv'\n",
    "dictfile = 'ADNI1_all_data/FOXLABBSI_DICT_03_27_20.csv'\n",
    "keyword = \"volume\"\n",
    "df = read_csv(file, dictfile, keyword)\n",
    "\n",
    "#make dir to save, name will be same as filename\n",
    "out = \"test\"\n",
    "make_dir(out)\n",
    "\n",
    "get_corr_mat(df, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RID VISCODE  EXAMDATE VERSION  ST100SV  ST101SV  ST102CV  ST103CV  ST104CV  \\\n",
      "0   15     m36   4/27/09  8/7/13      NaN     1140     2556     1809     2730   \n",
      "1   15     m06    5/2/06  8/7/13      NaN     1527     2748     1593     2772   \n",
      "2   15     m24  10/11/07  8/7/13      NaN     1100     2734     1651     2660   \n",
      "3   15     m12  10/16/06  8/7/13      NaN     1271     2742     1705     2816   \n",
      "4   15      bl  10/31/05  8/7/13      NaN     1327     3080     1742     2705   \n",
      "\n",
      "   ST105CV  ...  ST146HS  ST147SV  ST148SV  ST149SV  ST150SV   ST151SV  \\\n",
      "0     2106  ...  392.115   181075   185820   366895   214481  215448.0   \n",
      "1     2147  ...      NaN   188692   187295   375987   219660  218921.0   \n",
      "2     2339  ...  377.043   188368   186864   375232   216223  216144.0   \n",
      "3     2190  ...  354.918   187457   188328   375785   216942  214105.0   \n",
      "4     2222  ...  369.740   191836   190609   382445   217061  216157.0   \n",
      "\n",
      "   ST152SV  ST153SV  ST154SV  ST155SV  \n",
      "0   429929   167857   534752   909236  \n",
      "1   438581   171869   547856   931911  \n",
      "2   432367   168029   543261   923510  \n",
      "3   431047   172974   548759   921761  \n",
      "4   433218   167556   550001   928508  \n",
      "\n",
      "[5 rows x 157 columns]\n"
     ]
    }
   ],
   "source": [
    "##### UCSF Cross Sectional Free Surfer 3T data, this will be the baseline\n",
    "df = pd.read_csv('ADNI1_all_data/UCSFFSX51_ADNI1_3T_02_01_16.csv')\n",
    "#print(df.head())\n",
    "\n",
    "dict_df = pd.read_csv('ADNI1_all_data/UCSFFSX51_ADNI1_3T_DICT_11_01_13.csv')\n",
    "#filter out rows only with Volume\n",
    "dict_df = dict_df[dict_df[\"TEXT\"].str.contains(\"Volume\", case=False, na=False)]\n",
    "STcodes = dict_df['FLDNAME'].values\n",
    "#print(dict_df.head())\n",
    "#print(STcodes)\n",
    "\n",
    "extra_cols = ['RID','VISCODE','EXAMDATE','VERSION']\n",
    "column_needed = np.concatenate([extra_cols, STcodes])\n",
    "#print(column_needed)\n",
    "#cross reference df with dict_df\n",
    "df = df.loc[:,column_needed]\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-681171f4e57f>:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pat_df['EXAMDATE'] = pd.to_datetime(pat_df['EXAMDATE'], format='%m/%d/%y')\n"
     ]
    }
   ],
   "source": [
    "##create a directory to save all corr matrices in\n",
    "dirname = 'UCSF_cross_sectional_3T_2rows'\n",
    "parent_dir = os.getcwd()\n",
    "path = os.path.join(parent_dir, dirname)\n",
    "os.mkdir(path)\n",
    "\n",
    "#drop columns with all NAs\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# get patients\n",
    "patients = np.unique(df['RID'].values)\n",
    "print(len(patients))\n",
    "\n",
    "#I think fill rows with NA values at patient level for now, see how to do later\n",
    "for p in patients:\n",
    "    pat_df = df[df['RID'] == p]\n",
    "    \n",
    "    ##only take into account of patients with more than 3 rows\n",
    "    ##since 2 rows produce matrix of 1 and -1, and 1 row produces NA\n",
    "    ##will need to think about a better way\n",
    "    if len(pat_df.index) > 1:\n",
    "        #convert to datetime, then sort by time\n",
    "        pat_df['EXAMDATE'] = pd.to_datetime(pat_df['EXAMDATE'], format='%m/%d/%y')\n",
    "        pat_df = pat_df.sort_values(by=['EXAMDATE'])\n",
    "        #print(pat_df)\n",
    "\n",
    "        ##filling NA values, forward fill for now, MAY CHANGE!!!!\n",
    "        pat_df = pat_df.fillna(method='ffill')\n",
    "\n",
    "        #drop columns with all NAs\n",
    "        pat_df = pat_df.dropna(axis=1, how='all')\n",
    "\n",
    "        pad_df = pat_df.drop(['RID','VISCODE','VERSION'],axis=1)\n",
    "        corr_mat = pad_df.corr()\n",
    "\n",
    "        #output to csv for comparison later, maybe in R?\n",
    "        out_path = dirname + '/Patient_' + str(p) + '.csv'\n",
    "        corr_mat.to_csv(out_path)\n",
    "        \n",
    "        '''\n",
    "        ##basic correlation matrix plot, but turned out very messy\n",
    "        f = plt.figure(figsize=(19, 15))\n",
    "        plt.matshow(pad_df.corr(), fignum=f.number)\n",
    "        plt.xticks(range(pad_df.select_dtypes(['number']).shape[1]), pad_df.select_dtypes(['number']).columns, fontsize=14, rotation=90)\n",
    "        plt.yticks(range(pad_df.select_dtypes(['number']).shape[1]), pad_df.select_dtypes(['number']).columns, fontsize=14)\n",
    "        cb = plt.colorbar()\n",
    "        cb.ax.tick_params(labelsize=14)\n",
    "        plt.title('Correlation Matrix', fontsize=16);\n",
    "        '''\n",
    "        ##attempt 2 to use sns\n",
    "        #plot = sns.clustermap(corr_mat, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RID VISCODE  EXAMDATE  VERSION IMAGE_UID  RUNDATE    STATUS  \\\n",
      "0    2      sc   8/26/05  3/21/16    I35475  3/21/16  COMPLETE   \n",
      "1    3      sc    9/1/05  3/21/16    I32237  3/21/16  COMPLETE   \n",
      "2    4      sc   9/22/05  3/21/16    I64631  3/21/16  COMPLETE   \n",
      "3    5      sc    9/2/05  3/21/16    I32246  3/21/16  COMPLETE   \n",
      "4    6      sc  11/15/05  3/21/16    I33025  3/21/16  COMPLETE   \n",
      "\n",
      "                CBICA_ID      DATE     R702  ...      R199     R200     R201  \\\n",
      "0  011_S_0002_2005-08-26   8/26/05  1784710  ...  12577.70  7531.16  6862.94   \n",
      "1  011_S_0003_2005-09-01    9/1/05  1785950  ...   9596.26  6754.81  5647.18   \n",
      "2  022_S_0004_2005-09-22   9/22/05  1619320  ...  10444.50  7522.30  7652.39   \n",
      "3  011_S_0005_2005-09-02    9/2/05  1655680  ...  10243.40  5616.39  5902.29   \n",
      "4  100_S_0006_2005-11-15  11/15/05  1528520  ...   8364.14  5948.50  6253.38   \n",
      "\n",
      "      R202     R203     R204     R205     R206     R207  update_stamp  \n",
      "0  8957.96  9767.36  3077.59  2563.72  1338.33  1044.69       02:36.0  \n",
      "1  8133.22  7992.18  3008.82  3520.32  1148.99  1203.53       02:36.0  \n",
      "2  8225.52  8943.81  2867.52  2141.69  1515.77  1755.20       02:36.0  \n",
      "3  8467.85  7683.51  2973.72  2405.68  1724.79  1643.91       02:36.0  \n",
      "4  5931.44  6659.54  2321.83  2245.08  1261.12  1250.46       02:36.0  \n",
      "\n",
      "[5 rows x 269 columns]\n"
     ]
    }
   ],
   "source": [
    "###### UPenn Hierarchical Parcellation of MRI Using Multi-atlas Labeling\n",
    "### does not work, only 1 row/patient\n",
    "upenn_df = pd.read_csv('ADNI1_all_data/UPENNROI_MARS_06_01_16.csv')\n",
    "#print(upenn_df.head())\n",
    "\n",
    "##based on description looks like all are volume, so will use all columns\n",
    "upenn_dict_df = pd.read_csv('ADNI1_all_data/UPENNROI_MARS_DICT_06_01_16.csv')\n",
    "\n",
    "#drop columns with all NAs\n",
    "upenn_df = upenn_df.dropna(axis=1, how='all')\n",
    "\n",
    "# get patients\n",
    "upenn_patients = np.unique(upenn_df['RID'].values)\n",
    "#print(upenn_patients)\n",
    "\n",
    "#I think fill rows with NA values at patient level for now, see how to do later\n",
    "# for p in upenn_patients:\n",
    "#     pat_df = upenn_df[upenn_df['RID'] == p]\n",
    "#     print(pat_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RID VISCODE    EXAMDATE     VERSION  ST100SV  ST101SV  ST102CV  ST103CV  \\\n",
      "0    3     m06  2006-03-13  2009-07-01      NaN     1498     2927     1904   \n",
      "1    3     m12  2006-09-12  2009-07-01      NaN     1519     2935     1826   \n",
      "2    3     m24  2007-09-12  2009-07-02      NaN     1541     3038     1669   \n",
      "3    3      sc  2005-09-01  2009-07-01      NaN     1661     3261     1936   \n",
      "4    4     m06  2006-05-25  2009-08-24      NaN     1285     3021     2110   \n",
      "\n",
      "   ST104CV  ST105CV  ...  ST91CV  ST92SV  ST93CV  ST94CV  ST95CV  ST96SV  \\\n",
      "0     3416     2245  ...    8211     NaN    2236   13139    6003   29544   \n",
      "1     3275     2271  ...    8050     NaN    2115   13082    6072   29862   \n",
      "2     3284     2160  ...    7615     NaN    2147   12711    6065   32496   \n",
      "3     3278     2040  ...    8550     NaN    2362   13566    5892   28288   \n",
      "4     2638     2787  ...   10703     NaN    2003   11276    6884   19162   \n",
      "\n",
      "   ST97CV  ST98CV  ST99CV  ST9SV  \n",
      "0    7065    4253   10022   2808  \n",
      "1    7283    4158    9758   2939  \n",
      "2    6781    3901    9237   2987  \n",
      "3    7079    4046   10097   2863  \n",
      "4    7491    3838   10872   1396  \n",
      "\n",
      "[5 rows x 132 columns]\n"
     ]
    }
   ],
   "source": [
    "######### UCSF Longitutinal FreeSurfer\n",
    "longi_df = pd.read_csv('ADNI1_all_data/UCSFFSL_02_01_16.csv')\n",
    "# print(longi_df.head())\n",
    "\n",
    "longi_dict_df = pd.read_csv('ADNI1_all_data/UCSFFSL_DICT_11_01_13.csv')\n",
    "#filter out rows only with Volume\n",
    "longi_dict_df = longi_dict_df[longi_dict_df[\"TEXT\"].str.contains(\"Volume\", case=False, na=False)]\n",
    "longi_STcodes = longi_dict_df['FLDNAME'].values\n",
    "# print(longi_dict_df.head())\n",
    "# print(longi_STcodes)\n",
    "\n",
    "longi_extra_cols = ['RID','VISCODE','EXAMDATE','VERSION']\n",
    "longi_column_needed = np.concatenate([longi_extra_cols, longi_STcodes])\n",
    "#print(longi_column_needed)\n",
    "#cross reference df with dict_df\n",
    "longi_df = longi_df.loc[:,longi_column_needed]\n",
    "print(longi_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-52-6c7fc0c266ed>:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pat_df['EXAMDATE'] = pd.to_datetime(pat_df['EXAMDATE'], format='%Y-%m-%d')\n"
     ]
    }
   ],
   "source": [
    "##create a directory to save all corr matrices in for longitudinal\n",
    "logi_dirname = 'UCSF_longitudinal'\n",
    "logi_path = os.path.join(parent_dir, logi_dirname)\n",
    "os.mkdir(logi_path)\n",
    "\n",
    "#drop columns with all NAs\n",
    "longi_df = longi_df.dropna(axis=1, how='all')\n",
    "\n",
    "# get patients\n",
    "longi_patients = np.unique(longi_df['RID'].values)\n",
    "#print(longi_patients)\n",
    "\n",
    "#I think fill rows with NA values at patient level for now, see how to do later\n",
    "for p in longi_patients:\n",
    "    pat_df = longi_df[longi_df['RID'] == p]\n",
    "    \n",
    "    ##only take into account of patients with more than 3 rows\n",
    "    ##since 2 rows produce matrix of 1 and -1, and 1 row produces NA\n",
    "    ##will need to think about a better way\n",
    "    if len(pat_df.index) > 2:\n",
    "        #print(pat_df)\n",
    "        #convert to datetime, then sort by time\n",
    "        pat_df['EXAMDATE'] = pd.to_datetime(pat_df['EXAMDATE'], format='%Y-%m-%d')\n",
    "        pat_df = pat_df.sort_values(by=['EXAMDATE'])\n",
    "        #print(pat_df)\n",
    "    \n",
    "        ##filling NA values, ffill for now, MAY CHANGE!!!!\n",
    "        pat_df = pat_df.fillna(method='ffill')\n",
    "\n",
    "        #drop columns with all NAs\n",
    "        pat_df = pat_df.dropna(axis=1, how='all')\n",
    "\n",
    "        #print(pat_df)\n",
    "\n",
    "        pad_df = pat_df.drop(['RID','VISCODE','VERSION','EXAMDATE'],axis=1) \n",
    "        corr_mat = pad_df.corr()\n",
    "        #print(corr_mat)\n",
    "\n",
    "        #output to csv for comparison later, maybe in R?\n",
    "        logi_out_path = logi_dirname + '/Patient_' + str(p) + '.csv'\n",
    "        corr_mat.to_csv(logi_out_path)\n",
    "\n",
    "        ##visualization use sns\n",
    "        #plot = sns.clustermap(corr_mat, figsize=(10, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
